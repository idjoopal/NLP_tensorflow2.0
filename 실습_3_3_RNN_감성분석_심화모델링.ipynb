{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습_3_3_RNN_감성분석_심화모델링.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idjoopal/NLP_tensorflow2.0/blob/main/%EC%8B%A4%EC%8A%B5_3_3_RNN_%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D_%EC%8B%AC%ED%99%94%EB%AA%A8%EB%8D%B8%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQuwLrfneJGq"
      },
      "source": [
        "# 실습 3. RNN을 이용한 😀감정분석😑 모델 학습하기\n",
        "\n",
        "\n",
        "\n",
        "<b>학습 목표:    \n",
        "- LSTM, GRU 등 다양한 RNN 계열 셀들을 활용해본다.\n",
        "- Bidirectional RNN, Multi-layer RNN, 모델 앙상블을 모델링해본다.\n",
        "</b>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI5VEKjCVzQz"
      },
      "source": [
        "## #0. 실습 준비하기\n",
        "지난 실습에서는 SimpleRNN을 사용해 감성분석 모델링을 진행했습니다.    \n",
        "이번 시간에는 이론으로 학습한 다양한 셀 구조와 모델 아키텍처를 사용해 모델링을 진행해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cg9V5xCV-YJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb37f1b1-4a9b-41b9-a7d2-7aa3b295f083"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ695haKKAwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f14187-34f6-4ab0-8a5e-b30bf4c01824"
      },
      "source": [
        "## train, validation, test 데이터 로딩\n",
        "!cp \"/content/gdrive/My Drive/NLP/utils.py\" \"/content\"\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "with open(\"/content/gdrive/My Drive/NLP/Sentiment_prepro_data.pkl\", \"rb\") as f:\n",
        "  prepro_data = pickle.load(f)\n",
        "train_ids = prepro_data[\"train_ids\"]\n",
        "train_labels = prepro_data[\"train_labels\"]\n",
        "val_ids = prepro_data[\"val_ids\"]\n",
        "val_labels = prepro_data[\"val_labels\"]\n",
        "test_ids = prepro_data[\"test_ids\"]\n",
        "test_labels = prepro_data[\"test_labels\"]\n",
        "label_map = prepro_data[\"label_map\"]\n",
        "print(len(train_ids), len(train_labels), len(val_ids), len(val_labels), len(test_ids), len(test_labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49999 49999 9999 9999 10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLMDpntkKOY7"
      },
      "source": [
        "## 단어사전 & text_encoder 로딩\n",
        "from utils import TextEncoder\n",
        "import json\n",
        "with open(\"/content/gdrive/My Drive/NLP/Sentiment_vocab.json\", \"r\") as f:\n",
        "  new_vocab_list = json.loads(f.read())\n",
        "\n",
        "text_encoder = TextEncoder(new_vocab_list)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Cnajwnc73B"
      },
      "source": [
        "\"\"\" CBOW 워드벡터 로딩 \"\"\"\n",
        "\n",
        "## final_embeddings: 70002개 토큰에 대한 워드 벡터 매트릭스 shape=(70002, 128)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/NLP/vecs.tsv\") as f:\n",
        "  vecs = [v.strip() for v in f.readlines()]\n",
        "  final_embeddings = [v.split(\"\\t\") for v in vecs]\n",
        "  final_embeddings = np.array(final_embeddings, dtype=\"float32\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zo7pgURKdFq"
      },
      "source": [
        "## #1. 모델링 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39iPCdwGTjzk"
      },
      "source": [
        "### MODEL1: LSTM 셀 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u21E5JCF75xX"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAQKP1aQI0G5"
      },
      "source": [
        "LSTM 셀은 tensorflow.keras.layers에 있는 LSTM 레이어를 사용하면 됩니다.   \n",
        "사용하는 방법은 SimpleRNN과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcDr8GlZTqqV"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model1 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     LSTM(rnn_hidden_dim),\n",
        "     Dense(rnn_hidden_dim, activation= \"relu\"),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlpgWelVIMXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea354f3-c6dd-40f8-a862-301fb8cf85e6"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,037,364\n",
            "Trainable params: 11,037,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nJZ8o6v7kih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7848624-cfa2-413f-cd3a-f190f8d48535"
      },
      "source": [
        "\"\"\"CBOW로 학습된 워드 임베딩을 Initialize 해주기\"\"\"\n",
        "import random\n",
        "org_vocab_size = final_embeddings.shape[0]\n",
        "rand_initial = np.random.uniform(-1,1,size=[vocab_size-org_vocab_size,embedding_dim])\n",
        "# CBOW 학습된 임베딩 + 랜덤 initialize한 weight를 모델의 weight에 대입\n",
        "initial_weight = np.append(final_embeddings, rand_initial, axis = 0)\n",
        "model1.weights[0].assign(initial_weight)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[ 3.9256822e-02, -2.4412179e-02, -7.6701492e-04, ...,\n",
              "         4.9325500e-02,  4.3148886e-02, -4.0991127e-02],\n",
              "       [ 4.2455843e-01,  2.4667573e-01,  1.9708332e-01, ...,\n",
              "        -5.0499272e-02, -1.7417309e-01, -4.6320158e-01],\n",
              "       [ 1.0858837e+00, -1.2546027e+00, -1.2321458e+00, ...,\n",
              "         8.1983000e-01, -7.0880622e-01,  5.9558034e-01],\n",
              "       ...,\n",
              "       [ 8.6399156e-01,  5.1305711e-01, -6.8411499e-01, ...,\n",
              "        -5.7908010e-01, -7.9767889e-01, -3.1554498e-02],\n",
              "       [-1.2429511e-01,  8.2666171e-01,  1.4569159e-01, ...,\n",
              "        -2.5143108e-01, -8.0339712e-01,  1.0780119e-01],\n",
              "       [ 8.0013990e-01,  5.3400260e-01,  6.3544881e-01, ...,\n",
              "        -5.1082349e-01, -7.2256207e-01,  5.3883684e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nPJiGW1q92"
      },
      "source": [
        "## 모델 컴파일\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9vODjnL8KuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb70146-ea69-4e51-a1c0-756d5d77f8ef"
      },
      "source": [
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model1.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 0.5132 - accuracy: 0.7363 - val_loss: 0.4212 - val_accuracy: 0.8070\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 0.3532 - accuracy: 0.8460 - val_loss: 0.3952 - val_accuracy: 0.8219\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 16s 64ms/step - loss: 0.2933 - accuracy: 0.8781 - val_loss: 0.4116 - val_accuracy: 0.8243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT1NNPJ2fdE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9199b5c8-ba63-402d-df13-0324e20022d5"
      },
      "source": [
        "## 테스트 데이터에 대해 성능 평가\n",
        "model1.evaluate(test_ids, test_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.8102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43346041440963745, 0.8101999759674072]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFxF0B3SjgOh"
      },
      "source": [
        "### MODEL2: Bi-LSTM 모델 만들기\n",
        "\n",
        "Bi-RNN 모델은 keras.layers의 Bidirectional Layer로 RNN계열 레이어를 감싸서 코딩할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7tbxfLsjLOD"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Bidirectional\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model2 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     Bidirectional(LSTM(rnn_hidden_dim)),\n",
        "     Dense(rnn_hidden_dim, activation= \"relu\"),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9xC_2XgkT76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f28b8e-0b15-427f-eaf2-52262cec49da"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100)               71600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,075,664\n",
            "Trainable params: 11,075,664\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XbyBe5ZJI8a"
      },
      "source": [
        "👉bidirectional 레이어를 타고 나온 hidden vector의 차원이 100차원인 것을 확인할 수 있습니다.   \n",
        "orward LSTM에서 나온 50차원의 벡터와 backward LSTM에서 나온 50차원의 벡터를 concatenate했기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "925t5x3jkZuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b452ee-5242-4d02-b453-f44c5582245b"
      },
      "source": [
        "model2.weights[0].assign(initial_weight)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[ 3.9256822e-02, -2.4412179e-02, -7.6701492e-04, ...,\n",
              "         4.9325500e-02,  4.3148886e-02, -4.0991127e-02],\n",
              "       [ 4.2455843e-01,  2.4667573e-01,  1.9708332e-01, ...,\n",
              "        -5.0499272e-02, -1.7417309e-01, -4.6320158e-01],\n",
              "       [ 1.0858837e+00, -1.2546027e+00, -1.2321458e+00, ...,\n",
              "         8.1983000e-01, -7.0880622e-01,  5.9558034e-01],\n",
              "       ...,\n",
              "       [ 8.6399156e-01,  5.1305711e-01, -6.8411499e-01, ...,\n",
              "        -5.7908010e-01, -7.9767889e-01, -3.1554498e-02],\n",
              "       [-1.2429511e-01,  8.2666171e-01,  1.4569159e-01, ...,\n",
              "        -2.5143108e-01, -8.0339712e-01,  1.0780119e-01],\n",
              "       [ 8.0013990e-01,  5.3400260e-01,  6.3544881e-01, ...,\n",
              "        -5.1082349e-01, -7.2256207e-01,  5.3883684e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzLqEbAHkeZ0"
      },
      "source": [
        "## 모델 컴파일\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIsxg_ifkhlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20eea686-06ea-48ab-fe88-483dd6528f38"
      },
      "source": [
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 20s 78ms/step - loss: 0.5107 - accuracy: 0.7359 - val_loss: 0.4024 - val_accuracy: 0.8157\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.3466 - accuracy: 0.8483 - val_loss: 0.3852 - val_accuracy: 0.8296\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.2812 - accuracy: 0.8843 - val_loss: 0.3800 - val_accuracy: 0.8324\n",
            "Epoch 4/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.2316 - accuracy: 0.9089 - val_loss: 0.4109 - val_accuracy: 0.8254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuLPw7XGkktO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9b444d-eb38-437d-f410-76b099aadb02"
      },
      "source": [
        "## 테스트 데이터에 대해 성능 평가\n",
        "model2.evaluate(test_ids, test_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4264 - accuracy: 0.8172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42643100023269653, 0.8172000050544739]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAAvjbqokw7o"
      },
      "source": [
        "### MODEL3: Multi-layer-LSTM 모델 만들기\n",
        "\n",
        "Multi-layer RNN 모델을 만들기 위해서는 하단의 RNN 레이어에서 return_sequences 옵션을 True로 설정해야 합니다.   \n",
        "다음 레이어에서는 이전 레이어에서 반환한 시퀀스 hidden state를 인풋으로 받기 때문입니다.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23lOVrGvkmMe"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model3 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     GRU(rnn_hidden_dim, return_sequences = True),\n",
        "     Dropout(0.2),\n",
        "     LSTM(rnn_hidden_dim, return_sequences = False),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZxHufNhlEJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ab0bc6-024d-4125-e463-14c656237099"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 50)          27000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 50)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,046,214\n",
            "Trainable params: 11,046,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY4hiTajlGUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9ed4fb-4812-462e-c301-2845661adf89"
      },
      "source": [
        "model3.weights[0].assign(initial_weight)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[ 3.9256822e-02, -2.4412179e-02, -7.6701492e-04, ...,\n",
              "         4.9325500e-02,  4.3148886e-02, -4.0991127e-02],\n",
              "       [ 4.2455843e-01,  2.4667573e-01,  1.9708332e-01, ...,\n",
              "        -5.0499272e-02, -1.7417309e-01, -4.6320158e-01],\n",
              "       [ 1.0858837e+00, -1.2546027e+00, -1.2321458e+00, ...,\n",
              "         8.1983000e-01, -7.0880622e-01,  5.9558034e-01],\n",
              "       ...,\n",
              "       [ 8.6399156e-01,  5.1305711e-01, -6.8411499e-01, ...,\n",
              "        -5.7908010e-01, -7.9767889e-01, -3.1554498e-02],\n",
              "       [-1.2429511e-01,  8.2666171e-01,  1.4569159e-01, ...,\n",
              "        -2.5143108e-01, -8.0339712e-01,  1.0780119e-01],\n",
              "       [ 8.0013990e-01,  5.3400260e-01,  6.3544881e-01, ...,\n",
              "        -5.1082349e-01, -7.2256207e-01,  5.3883684e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mAFetXAlK4A"
      },
      "source": [
        "## 모델 컴파일\n",
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M78FuhlmlOgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22afe908-a47f-41e8-833f-1a78768f812e"
      },
      "source": [
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model3.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 20s 79ms/step - loss: 0.5163 - accuracy: 0.7362 - val_loss: 0.3982 - val_accuracy: 0.8140\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.3508 - accuracy: 0.8478 - val_loss: 0.3778 - val_accuracy: 0.8339\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.2895 - accuracy: 0.8801 - val_loss: 0.3729 - val_accuracy: 0.8360\n",
            "Epoch 4/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.2469 - accuracy: 0.9030 - val_loss: 0.3961 - val_accuracy: 0.8359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RvsQmKzlRBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5947a9c2-f792-4e9a-839a-f18ebb01412e"
      },
      "source": [
        "## 테스트 데이터에 대해 성능 평가\n",
        "model3.evaluate(test_ids, test_labels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4202 - accuracy: 0.8222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4202301800251007, 0.8222000002861023]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BmzCfNmCE3"
      },
      "source": [
        "### MODEL4: 세 모델의 결과 앙상블하기\n",
        "마지막으로 위에서 학습한 세 모델을 앙상블하는 코드입니다.   \n",
        "세 개의 모델을 독립적으로 학습한 후 결과를 앙상블하면 정확도를 높일 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEEFTHlblT2y"
      },
      "source": [
        "def predict(test_ids):\n",
        "  res1 = model1.predict(test_ids)\n",
        "  res2 = model2.predict(test_ids)\n",
        "  res3 = model3.predict(test_ids)\n",
        "  result = (res1 + res2 + res3) / 3\n",
        "  return result"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzww4mdzm28X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1c7119-03bf-4d2a-882d-b600aab95110"
      },
      "source": [
        "prediction = predict(test_ids)\n",
        "prediction"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.734816  , 0.26518402],\n",
              "       [0.7273212 , 0.27267882],\n",
              "       [0.32887414, 0.6711259 ],\n",
              "       ...,\n",
              "       [0.9857342 , 0.01426579],\n",
              "       [0.9930784 , 0.00692162],\n",
              "       [0.417093  , 0.58290696]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrgttjzZ0GHV"
      },
      "source": [
        "👉predict 함수는 세 모델이 예측한 결과를 평균한 확률값을 아웃풋으로 반환합니다.    \n",
        "\n",
        "최종적으로 예측을 하기 위해서는 이 확률값을 카테고리로 변경해야 하겠지요?   \n",
        "np.argmax 함수는 주어진 축에 대해 최대값의 위치를 찾아주는 함수입니다.   \n",
        "이 함수를 사용해 확률값이 가장 높은 카테고리를 모델 예측치로 사용할 수 있습니다.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdH4Z7Ulm6JC"
      },
      "source": [
        "\"\"\" catecory로 변경 \"\"\"\n",
        "prediction = np.argmax(prediction, axis = 1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TycNYyY5nI4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58181d78-6686-4c05-9c23-a600b79b011a"
      },
      "source": [
        "print(\"TEST ACCURACY:\")\n",
        "sum(prediction == test_labels) / len(test_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST ACCURACY:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SUIcOx7KWGP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3yyOsTqKiR_"
      },
      "source": [
        "## #2. DAILY MISSION 🙌\n",
        "\n",
        "아래의 세 모델은 RNN을 사용하여 만든 감성분석 모델입니다.   \n",
        "그런데 무슨 문제인지, 학습이 잘 이루어지지 않고 있습니다.   \n",
        "모델을 살펴보고, 어떤 오류가 있는지 찾아 디버깅한 후 파일을 제출해주세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh7ugE6YLqHJ"
      },
      "source": [
        "#### model_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_8MkMZZKYpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b94c4f9-c195-497e-b7a1-c0c9764ffd88"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_1 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     GRU(rnn_hidden_dim),\n",
        "     Dense(rnn_hidden_dim, activation= \"relu\"),\n",
        "     Dense(2, activation= \"softmax\")]\n",
        ")\n",
        "model_1.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 50)                27000     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,028,564\n",
            "Trainable params: 11,028,564\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zoNJrL0LbG4"
      },
      "source": [
        "- 오류가 있는 부분:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ylbdC4LOtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1dba53-362a-4b1d-e142-64eef9df39eb"
      },
      "source": [
        "model_1.weights[0].assign(initial_weight)\n",
        "## 모델 컴파일\n",
        "model_1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_1.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])\n",
        "\n",
        "model_1.evaluate(test_ids, test_labels)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.5339 - accuracy: 0.7155 - val_loss: 0.4156 - val_accuracy: 0.8111\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 17s 67ms/step - loss: 0.3559 - accuracy: 0.8459 - val_loss: 0.3778 - val_accuracy: 0.8355\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 17s 66ms/step - loss: 0.2895 - accuracy: 0.8795 - val_loss: 0.3784 - val_accuracy: 0.8376\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3862 - accuracy: 0.8273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38617417216300964, 0.8273000121116638]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF0s5gmELuPF"
      },
      "source": [
        "#### model_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L-rFAuoLXag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a136fb04-7efd-45e0-8189-20ee533a511d"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_2 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     GRU(rnn_hidden_dim, return_sequences=True),\n",
        "     GRU(rnn_hidden_dim, return_sequences=False),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 50)          27000     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 50)                15300     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,041,314\n",
            "Trainable params: 11,041,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1skBuhBsMAFy"
      },
      "source": [
        "- 오류가 있는 부분:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQJ7Ewv5L4Wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0ca793-3a0c-437c-91af-d8097631e408"
      },
      "source": [
        "model_2.weights[0].assign(initial_weight)\n",
        "## 모델 컴파일\n",
        "model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])\n",
        "\n",
        "model_2.evaluate(test_ids, test_labels)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 19s 76ms/step - loss: 0.5090 - accuracy: 0.7401 - val_loss: 0.4335 - val_accuracy: 0.8006\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.3507 - accuracy: 0.8478 - val_loss: 0.3754 - val_accuracy: 0.8364\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.2877 - accuracy: 0.8819 - val_loss: 0.3912 - val_accuracy: 0.8380\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4027 - accuracy: 0.8287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4027133285999298, 0.8287000060081482]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLDlRLqMDnS"
      },
      "source": [
        "#### model_3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2q48ENcMFS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21adb010-da12-4745-9331-e7070dc18c25"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_3 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     LSTM(rnn_hidden_dim),\n",
        "     Dense(rnn_hidden_dim, activation=\"relu\"),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")\n",
        "\n",
        "\n",
        "model_3.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,037,364\n",
            "Trainable params: 11,037,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfsVmqCyMCSB"
      },
      "source": [
        "- 오류가 있는 부분:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo_gfBUEMFPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ca9876-12f9-44ec-f947-349c4a896983"
      },
      "source": [
        "model_3.weights[0].assign(initial_weight)\n",
        "## 모델 컴파일\n",
        "model_3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_3.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])\n",
        "\n",
        "model_3.evaluate(test_ids, test_labels)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 19s 74ms/step - loss: 0.5193 - accuracy: 0.7313 - val_loss: 0.4148 - val_accuracy: 0.8131\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 16s 66ms/step - loss: 0.3511 - accuracy: 0.8452 - val_loss: 0.3935 - val_accuracy: 0.8285\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 16s 66ms/step - loss: 0.2900 - accuracy: 0.8803 - val_loss: 0.3956 - val_accuracy: 0.8298\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.8203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41288793087005615, 0.8202999830245972]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}